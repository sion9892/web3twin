# Step2 구현 가능성 및 성능 분석

## 요구사항 정리

### 1번 방식: 자신의 팔로워, 팔로잉 중에서 트윈 찾기
- 현재 코드: 팔로워/팔로잉 각각 **100명씩**만 가져옴 (`limit=100`)
- 요구사항: **전체** 팔로워/팔로잉에서 트윈 찾기

### 2번 방식: 팔로워/팔로잉 < 50명인 경우
- 원래 팔로워/팔로잉 + 상위 랭킹 1-50위 풀에서 선택

---

## 현재 구현 상태

### API 제약사항
- **Neynar API** `getFollowers`/`getFollowing`:
  - `limit` 파라미터로 최대 가져올 수 있는 수 제한
  - 페이징 지원 여부: **확인 필요** (일반적으로 `cursor` 기반)
  - 한 번에 가져올 수 있는 최대 limit: **약 100~1000명** (API 문서 확인 필요)

### 현재 코드 로직
```typescript
// Step2Preview.tsx
const [followers, following] = await Promise.all([
  getFollowers(userInfo.fid, 100),  // 최대 100명
  getFollowing(userInfo.fid, 100),  // 최대 100명
]);

const SAMPLE_SIZE = 40; // 40명만 분석
const sampledCandidates = sampleCandidates(allCandidates, SAMPLE_SIZE);
```

---

## 구현 가능성 분석

### 1번 방식: 전체 팔로워/팔로잉에서 트윈 찾기

#### ✅ 구현 가능 (단, 제약사항 있음)

**방법 A: 페이징을 사용한 전체 가져오기**
- Neynar API가 `cursor` 기반 페이징 지원한다면:
  ```typescript
  // 의사코드
  let allFollowers = [];
  let cursor = null;
  do {
    const response = await getFollowers(fid, 100, cursor);
    allFollowers.push(...response.users);
    cursor = response.next_cursor;
  } while (cursor);
  ```
- **API 호출 횟수**: 팔로워 수 / 100 (반올림)
- **제약사항**: API Rate Limit 확인 필요

**방법 B: 샘플링 방식 (현재 접근)**
- 전체를 다 가져오지 않고, 최대한 많이 가져온 후 샘플링
- **장점**: 빠름, Rate Limit 영향 적음
- **단점**: 일부 팔로워는 누락될 수 있음

#### 현재 커버 가능한 최대 수
- **현재**: 팔로워 100명 + 팔로잉 100명 = **최대 200명** (중복 제거 시 더 적음)
- **개선 후** (limit 증가):
  - limit=1000: **최대 2000명**
  - limit=5000: **최대 10000명**
  - limit=10000: **최대 20000명** (Rate Limit 주의)

#### 제약사항
1. **API Rate Limit**: Neynar API의 시간당 요청 제한
2. **페이징 지원 여부**: cursor 기반 페이징이 필요한지 확인 필요
3. **응답 시간**: 팔로워가 많을수록 여러 번의 API 호출 필요

---

### 2번 방식: 팔로워/팔로잉 < 50명인 경우 처리

#### ✅ 구현 가능

```typescript
let allCandidates = mergeAndDedupeCandidates(followers, following);

if (allCandidates.length < 50) {
  // 상위 랭킹 1-50위 가져오기
  const topUsers = await getTopRankedUsers(1, 50);
  
  // 팔로워/팔로잉 + 상위 랭킹 합치기
  allCandidates = [...allCandidates, ...topUsers];
  
  // 중복 제거
  allCandidates = dedupe(allCandidates);
}
```

**필요한 API:**
- 상위 랭킹 사용자 목록 API (Neynar에서 제공하는지 확인 필요)
- 또는 하드코딩된 인기 사용자 목록 (현재 `Step2Preview.tsx`에 있음)

---

## 시간복잡도 분석

### 전체 프로세스 단계별 시간복잡도

#### Step 1: 팔로워/팔로잉 가져오기
- **시간복잡도**: `O(F + G)` where F = 팔로워 수, G = 팔로잉 수
- **실제 시간**: API 호출 시간에 의존
  - 단일 API 호출: **~200-500ms** (네트워크 지연)
  - 페이징 필요 시: **API 호출 횟수 × 200-500ms**

#### Step 2: 후보자 샘플링
- **시간복잡도**: `O(N)` where N = 전체 후보자 수
- **실제 시간**: **~1-5ms** (메모리 내 연산)

#### Step 3: 각 후보자의 Cast 가져오기
- **시간복잡도**: `O(S × C)` where S = 샘플 크기(40), C = cast 가져오기 시간
- **실제 시간**: 
  - 각 후보자당: **~200-500ms** (API 호출)
  - 총 **40명 × 200-500ms = 8-20초** (순차 호출 시)
  - 병렬 호출 시: **~2-5초** (Rate Limit 주의)

#### Step 4: 유사도 계산
- **시간복잡도**: `O(S × W)` where W = 평균 단어 수/후보자당
- **실제 시간**: **~10-50ms** (메모리 내 연산)

---

## 팔로워 수별 예상 소요 시간

### 가정
- API 응답 시간: **300ms/요청**
- Cast 가져오기: **300ms/후보자**
- 유사도 계산: **10ms/후보자**
- **SAMPLE_SIZE = 40** (고정)

### 시나리오별 계산

#### 시나리오 1: 팔로워 100명
```
1. 팔로워 가져오기: 1번 API 호출 = 300ms
2. 팔로잉 가져오기: 1번 API 호출 = 300ms
3. 후보자 샘플링: 5ms
4. 40명 Cast 가져오기: 40 × 300ms = 12초 (순차) / 3초 (병렬 10개씩)
5. 유사도 계산: 40 × 10ms = 400ms

총 시간: 약 13-14초 (순차) / 4-5초 (병렬)
```

#### 시나리오 2: 팔로워 1,000명
```
1. 팔로워 가져오기: 10번 API 호출 = 3초 (순차) / 0.9초 (병렬 10개씩)
2. 팔로잉 가져오기: 10번 API 호출 = 3초 (순차) / 0.9초 (병렬 10개씩)
3. 후보자 샘플링: 10ms
4. 40명 Cast 가져오기: 40 × 300ms = 12초 (순차) / 3초 (병렬 10개씩)
5. 유사도 계산: 400ms

총 시간: 약 18-19초 (순차) / 5-6초 (병렬)
```

#### 시나리오 3: 팔로워 10,000명
```
1. 팔로워 가져오기: 100번 API 호출 = 30초 (순차) / 9초 (병렬 10개씩)
2. 팔로잉 가져오기: 100번 API 호출 = 30초 (순차) / 9초 (병렬 10개씩)
3. 후보자 샘플링: 50ms
4. 40명 Cast 가져오기: 12초 (순차) / 3초 (병렬)
5. 유사도 계산: 400ms

총 시간: 약 72초 (순차) / 21-22초 (병렬)
```

#### 시나리오 4: 팔로워 100,000명
```
1. 팔로워 가져오기: 1,000번 API 호출 = 300초 (순차) / 90초 (병렬 10개씩)
2. 팔로잉 가져오기: 1,000번 API 호출 = 300초 (순차) / 90초 (병렬 10개씩)
3. 후보자 샘플링: 100ms
4. 40명 Cast 가져오기: 12초 (순차) / 3초 (병렬)
5. 유사도 계산: 400ms

총 시간: 약 612초 (10분, 순차) / 183초 (3분, 병렬)
```

#### 시나리오 5: 팔로워 1,000,000명
```
1. 팔로워 가져오기: 10,000번 API 호출 = 3,000초 (50분, 순차)
   → Rate Limit 위험! 병렬 제한적
2. 팔로잉 가져오기: 10,000번 API 호출 = 3,000초 (50분)
3. 후보자 샘플링: 500ms
4. 40명 Cast 가져오기: 12초 (순차) / 3초 (병렬)
5. 유사도 계산: 400ms

총 시간: 약 6,012초 (100분, 순차)
→ **실제로는 Rate Limit로 인해 더 오래 걸릴 수 있음**
```

---

## 최적화 방안

### 1. 샘플링 전략
- **현재**: 팔로워/팔로잉에서 랜덤 샘플링
- **개선**: 더 많은 수를 가져온 후 샘플링 (예: limit=5000)

### 2. 병렬 처리
- 팔로워/팔로잉 가져오기를 병렬로
- Cast 가져오기를 배치로 병렬 처리 (예: 10개씩)

### 3. 캐싱
- 팔로워/팔로잉 목록 캐싱 (예: 24시간)
- Cast 데이터 캐싱 (예: 1시간)

### 4. 제한된 분석
- 팔로워가 너무 많으면 (예: > 10,000명) 샘플링만 사용
- 또는 사용자에게 옵션 제공: "전체 분석" vs "빠른 분석"

### 5. 백그라운드 처리
- 대규모 분석은 백그라운드 작업으로 처리
- 웹소켓이나 폴링으로 진행 상황 업데이트

---

## 결론

### 구현 가능성
- ✅ **1번 방식**: 구현 가능 (페이징 지원 시)
  - **현재 커버**: 최대 200명 (limit=100)
  - **개선 후 커버**: 최대 10,000-20,000명 (limit=5000-10000)
  - **전체 커버**: 페이징 사용 시 이론적으로 무제한 (Rate Limit 제약)

- ✅ **2번 방식**: 구현 가능
  - 팔로워/팔로잉 < 50명 체크 후 상위 랭킹 추가

### 시간복잡도 요약
- **100명**: ~4-5초 (병렬 처리 시)
- **1,000명**: ~5-6초
- **10,000명**: ~21-22초
- **100,000명**: ~3분
- **1,000,000명**: ~100분 (Rate Limit 위험)

### 권장사항
1. **현실적인 limit 설정**: limit=5000 정도로 시작
2. **병렬 처리 구현**: 배치로 10-20개씩 병렬 호출
3. **진행 상황 표시**: 사용자에게 진행률 표시
4. **Rate Limit 대응**: 에러 처리 및 재시도 로직
5. **대규모 사용자 처리**: 샘플링 방식 권장 또는 백그라운드 처리


